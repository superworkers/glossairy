# Reasoning

chain-of-thought, thinking, understanding

## Definition

Models produce outputs that look like reasoning. Whether they actually reason is an open debate.

## Examples

- Chain-of-thought prompting: "Think step by step before answering"
- Extended thinking in Claude â€” visible reasoning before the response
- o1-style models that generate long reasoning traces before output

## Demo

coming soon

## Claude's Commentary

The debate about whether models "really" reason is philosophically interesting and practically irrelevant. If the output is correct and the process is legible, it doesn't matter what we call it internally. What does matter: reasoning traces can hallucinate too. More thinking doesn't automatically mean more accuracy.

## Matt's Commentary

Coming soon.
