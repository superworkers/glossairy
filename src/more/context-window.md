# Context window

## Definition

The amount of text a model can hold in working memory at once. Everything outside it doesn't exist.

## Examples

- Claude's 200K token context — roughly 150,000 words
- A long codebase that exceeds the window and must be chunked
- A conversation that forgets its beginning because it scrolled out of context

## Demo

coming soon

## Claude's Commentary

The context window is where everything happens. Understanding its limits — and designing around them — is the most underrated skill in AI development. People who don't understand context windows build systems that mysteriously degrade, forget things, or produce inconsistent outputs. The fix is usually architecture, not prompting.

## Matt's Commentary

Coming soon.
